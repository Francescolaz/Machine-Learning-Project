{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression\n",
    "\n",
    "*Ridge Regression* algorithm built from scratch under the form of the `Ridge()` Python class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression algorithm from scratch\n",
    "  \n",
    "class Ridge():\n",
    "      \n",
    "    # Create the Ridge object\n",
    "    def __init__(self, intercept, alpha): \n",
    "          \n",
    "        self.alpha = alpha            \n",
    "        self.intercept = intercept\n",
    "        \n",
    "          \n",
    "    # Train the algorithm on a Training Set\n",
    "    def fit(self, train_scaled_features, labels):\n",
    "        \n",
    "        labels = np.array(labels)\n",
    "        \n",
    "        # Learn Homogeneous Linear Predictors (add intercept as column of ones)\n",
    "        if self.intercept == True:\n",
    "            intercept_col = np.ones((train_scaled_features.shape[0],1))\n",
    "            train_scaled_features =  np.append(intercept_col, train_scaled_features, axis=1)\n",
    "            \n",
    "            # Compute the solution of the minimization problem\n",
    "            alpha_I = self.alpha * np.identity(train_scaled_features.shape[1])\n",
    "            alpha_I[0,0] = 0.0    # DO NOT penalize the intercept!\n",
    "        \n",
    "            inverse_mat = LA.inv(train_scaled_features.T @ train_scaled_features + alpha_I)\n",
    "            reg_coef = inverse_mat @ train_scaled_features.T @ labels\n",
    "            \n",
    "        else:\n",
    "            alpha_I = self.alpha * np.identity(train_scaled_features.shape[1])\n",
    "            inverse_mat = LA.inv(train_scaled_features.T @ train_scaled_features + alpha_I)\n",
    "            reg_coef = inverse_mat @ train_scaled_features.T @ labels\n",
    "        \n",
    "        self.reg_coef = reg_coef\n",
    "        self.train_scaled_features = train_scaled_features\n",
    "        \n",
    "    \n",
    "    # Evaluate the performance of the predictor output by the algorithm on a Test Set\n",
    "    def predict(self, test_scaled_features):\n",
    "        \n",
    "        test_scaled_features = np.matrix(test_scaled_features)\n",
    "            \n",
    "        if self.intercept == True:\n",
    "            intercept_col = np.ones((test_scaled_features.shape[0],1))\n",
    "            test_scaled_features =  np.append(intercept_col, test_scaled_features, axis=1)\n",
    "            \n",
    "        \n",
    "        predictions = np.array(test_scaled_features.dot(self.reg_coef))\n",
    "        \n",
    "        self.predictions = predictions\n",
    "        \n",
    "        return(self.predictions)\n",
    "    \n",
    "    \n",
    "    # Compute the Test Error (risk estimate) according to the square loss\n",
    "    def pred_err(self, true_labels):\n",
    "                \n",
    "        true_labels = np.array(true_labels)\n",
    "        ridge_loss = np.mean((true_labels - self.predictions)**2)\n",
    "            \n",
    "        return(np.round(ridge_loss,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine_Learning",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
