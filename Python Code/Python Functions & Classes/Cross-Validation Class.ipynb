{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-fold Cross-Validation and Validation Curve\n",
    "\n",
    "*K-fold Cross-Validation* algorithm built from scratch under the form of the `ValidationCurve()` Python class, used to perform Hyperparameter and Principal Components tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve with k-fold Cross-Validation algorithm from scratch\n",
    "\n",
    "class ValidationCurve(): \n",
    "      \n",
    "    # Create the ValidationCurve object\n",
    "    def __init__(self, features, labels, feat_scaling, include_intercept = True): \n",
    "        \n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.feat_scaling = feat_scaling\n",
    "        self.include_intercept = include_intercept\n",
    "        \n",
    "    # Display the Validation Curve for the Hyperparameter Tuning of the Ridge learner\n",
    "    def val_curve_ridge(self, grid_alpha, k_folds, seed, show_plot = True):\n",
    "        \n",
    "        # Arrays for tracking Training and Validation errors\n",
    "        train_errors = np.zeros((len(grid_alpha), k_folds))\n",
    "        cross_val_errors = np.zeros((len(grid_alpha), k_folds))\n",
    "        \n",
    "        # Random shuffle of the Features and Labels\n",
    "        idx = np.random.RandomState(seed = seed).permutation(len(self.features))\n",
    "        feat_shuff, labl_shuff = self.features.loc[idx, :], self.labels.loc[idx, :]\n",
    "        \n",
    "        # Features and Labels divided in k-number of folds\n",
    "        feat_folds, labl_folds = np.array_split(feat_shuff, k_folds), np.array_split(labl_shuff, k_folds)\n",
    "    \n",
    "        # Loop on the values of the Hyperparameter in the grid\n",
    "        for alp in range(0, len(grid_alpha)):\n",
    "            \n",
    "            # Loop over the Training and Validation folds\n",
    "            for i in range(0, k_folds):\n",
    "            \n",
    "                ridge_learner = Ridge(alpha = grid_alpha[alp], intercept = self.include_intercept)\n",
    "                        \n",
    "                # Features and Labels in the Validation fold at each iteration\n",
    "                f_val = feat_folds[i]\n",
    "                l_val = labl_folds[i]\n",
    "            \n",
    "                # Features and Labels in the Training folds at each iteration\n",
    "                f_train = feat_shuff.drop(f_val.index)\n",
    "                l_train = labl_shuff.drop(l_val.index)\n",
    "                \n",
    "                # Transform the Features without breaking the independence between Training and Validation folds\n",
    "                if self.feat_scaling is not None:\n",
    "                    transformer = features_transformation(self.feat_scaling)\n",
    "                    f_train = transformer.fit(f_train)\n",
    "                    f_val = transformer.test_transform(f_val)\n",
    "            \n",
    "            \n",
    "                # Train the predictor on the Training folds\n",
    "                ridge_learner.fit(f_train, l_train)\n",
    "            \n",
    "                # Compute the Validation Error (estimate of the risk)  according to the square loss                            \n",
    "                train_pred = ridge_learner.predict(f_train)\n",
    "                train_errors[alp, i] = np.mean((train_pred - l_train)**2)\n",
    "        \n",
    "                ridge_learner.predict(f_val)\n",
    "        \n",
    "                cross_val_errors[alp, i] = ridge_learner.pred_err(l_val)\n",
    "                \n",
    "        # Compute the average of the Validation Errors for each value of the Hyperparameter in the grid\n",
    "        val_score_mean = np.mean(cross_val_errors, axis=1)\n",
    "        \n",
    "        # Retrieve the best value of the Hyperparameter that lead to the lowest Risk Estimate\n",
    "        best_ind = np.where(val_score_mean == np.min(val_score_mean))\n",
    "        best_alpha = grid_alpha[best_ind]\n",
    "\n",
    "        self.best_alpha = best_alpha[0]\n",
    "        \n",
    "        train_score_mean = np.mean(train_errors, axis=1)\n",
    "        train_score_std = np.std(train_errors, axis=1)\n",
    "        val_score_std = np.std(cross_val_errors, axis=1)   \n",
    "            \n",
    "        # Plot the Validation Curve\n",
    "        if show_plot == True:\n",
    "            \n",
    "            plt.figure(figsize=(12,7))\n",
    "            plt.plot(grid_alpha, val_score_mean, 'o-', label='CV error estimate')\n",
    "            plt.plot(grid_alpha, train_score_mean, 'o-', label='Training error')\n",
    "            \n",
    "            plt.fill_between(grid_alpha, val_score_mean - val_score_std, \n",
    "                 val_score_mean + val_score_std, alpha=0.1, color='r', label = 'CV estimate std. deviation')\n",
    "            plt.fill_between(grid_alpha, train_score_mean - train_score_std, \n",
    "                train_score_mean + train_score_std, alpha=0.1, color='g', label = 'Train error std. deviation')\n",
    "        \n",
    "            plt.legend(loc = 'upper left')\n",
    "            #plt.title('Validation Curve - ' + str(self.feat_scaling))\n",
    "            plt.xlabel('alpha')\n",
    "            plt.ylabel('Average square loss')\n",
    "            plt.annotate('min.', xy=(grid_alpha[best_ind], val_score_mean[best_ind]), \n",
    "                xytext = (grid_alpha[best_ind], val_score_mean[best_ind]+0.01*val_score_mean[best_ind]),\n",
    "                         arrowprops=dict(arrowstyle=\"->\"))\n",
    "            plt.show()\n",
    "            \n",
    "            # Print a dictionary with teh Best Hyperparameter and the corresponding Risk Estimate\n",
    "            dict_cv = {'Best Hyperparameter': self.best_alpha, \n",
    "                       'Cross-Validation Risk Estimate': np.format_float_scientific(np.min(val_score_mean))}\n",
    "            self.dict_cv = dict_cv\n",
    "            print(dict_cv)\n",
    "            \n",
    "        return(train_errors, cross_val_errors)\n",
    "        \n",
    "        \n",
    "    # Select the best number of Principal Components according to the corresponding Risk Estimates\n",
    "    def val_curve_pca(self, grid_princomp, k_pcafolds, seed, show_plot = True):\n",
    "        \n",
    "        # Track the Training and Validation errors for each number of Principal Components\n",
    "        train_pca_curve_err = np.zeros((len(grid_princomp), k_pcafolds))\n",
    "        val_pca_curve_err = np.zeros((len(grid_princomp), k_pcafolds))\n",
    "        \n",
    "        # Random shuffle of the Features and Labels\n",
    "        idx_pca = np.random.RandomState(seed = seed).permutation(len(self.features))\n",
    "        feat_shuff_pca, labl_shuff_pca = self.features.loc[idx_pca, :], self.labels.loc[idx_pca, :]\n",
    "    \n",
    "        # Features and Labels divided in k-number of folds\n",
    "        feat_folds_pca, labl_folds_pca = np.array_split(feat_shuff_pca, k_pcafolds), np.array_split(labl_shuff_pca, k_pcafolds)\n",
    "    \n",
    "        # Loop on the number of Principal Components in the grid\n",
    "        for pc in range(0, len(grid_princomp)):\n",
    "        \n",
    "            # Loop over the Training and Validation folds\n",
    "            for i in range(0, k_pcafolds):\n",
    "            \n",
    "                ridge_learner = Ridge(alpha = self.best_alpha, intercept = self.include_intercept)\n",
    "                \n",
    "                # Features and Labels in the Validation fold at each iteration\n",
    "                f_val = feat_folds_pca[i]\n",
    "                l_val = labl_folds_pca[i]\n",
    "                \n",
    "                # Features and Labels in the Training folds at each iteration\n",
    "                f_train = feat_shuff_pca.drop(f_val.index)\n",
    "                l_train = labl_shuff_pca.drop(l_val.index)\n",
    "                \n",
    "                # Transform the Features without breaking the independence between the Training and Validation folds\n",
    "                if self.feat_scaling is not None:\n",
    "                    transformer = features_transformation(self.feat_scaling)\n",
    "                    f_train = transformer.fit(f_train)\n",
    "                    f_val = transformer.test_transform(f_val)\n",
    "                \n",
    "                # Perform PCA on the Training folds and project also the observations in the Validation fold\n",
    "                pca = PCA(f_train)\n",
    "                pca.singular_values()\n",
    "                \n",
    "                # Rewrite the Train and Validation Features with the lower dimensional ones\n",
    "                f_train = pca.projected_features(grid_princomp[pc], False)\n",
    "                f_val = pca.project_test(f_val)\n",
    "                \n",
    "                # Train the algorithm on the Training folds \n",
    "                ridge_learner.fit(f_train, l_train)\n",
    "                                               \n",
    "                train_pred = ridge_learner.predict(f_train)\n",
    "                train_pca_curve_err[pc, i] = np.mean((train_pred - l_train)**2)\n",
    "                                \n",
    "                # Predict the Labels in the Validation fold and compute the Validation error\n",
    "                ridge_learner.predict(f_val)\n",
    "                val_pca_curve_err[pc, i] = ridge_learner.pred_err(l_val)\n",
    "                \n",
    "        \n",
    "        # Compute the average Training and Validation Errors for each number of Principal Components\n",
    "        train_score_pca_mean = np.mean(train_pca_curve_err, axis = 1)\n",
    "        val_score_pca_mean = np.mean(val_pca_curve_err, axis = 1)\n",
    "            \n",
    "        # Retrieve the best number of Principal Components that lead to the lowest Risk Estimate\n",
    "        best_ind = np.where(val_score_pca_mean == np.min(val_score_pca_mean))\n",
    "        best_npc = grid_princomp[best_ind]\n",
    "\n",
    "        self.best_npc = best_npc[0]\n",
    "    \n",
    "        #train_score_pca_std = np.std(train_pca_curve_err, axis=1)                \n",
    "        #val_score_pca_std = np.std(val_pca_curve_err, axis=1)\n",
    "            \n",
    "        # Plot the new version of the Validation Curve\n",
    "        if show_plot == True:\n",
    "            \n",
    "            plt.figure(figsize=(12,7))\n",
    "            plt.plot(grid_princomp, val_score_pca_mean, 'o-', label='CV error estimate')\n",
    "            plt.plot(grid_princomp, train_score_pca_mean, 'o-', label='Training error')\n",
    "            \n",
    "            #plt.fill_between(grid_princomp, val_score_pca_mean - val_score_pca_std,                  \n",
    "            #    val_score_pca_mean + val_score_pca_std, alpha=0.1,color='r', label = 'CV estimate std. deviation')\n",
    "            #plt.fill_between(grid_princomp, train_score_pca_mean - train_score_pca_std, \n",
    "            #    train_score_pca_mean + train_score_pca_std,alpha=0.1,color='g',label ='Train error std. deviation')\n",
    "        \n",
    "            plt.legend(loc = 'upper left')                \n",
    "            #plt.title('Validation Curve - PCA')\n",
    "            plt.xlabel('principal components')\n",
    "            plt.ylabel('average square loss')\n",
    "            plt.annotate('min.', xy=(grid_princomp[best_ind], val_score_pca_mean[best_ind]), \n",
    "                xytext = (grid_princomp[best_ind], 2.5*val_score_pca_mean[best_ind]), \n",
    "                         arrowprops=dict(arrowstyle=\"->\"))\n",
    "            plt.show()\n",
    "            \n",
    "            dict_cv_pca = {'Best Number of Principal Components': self.best_npc, \n",
    "                           'Cross-Validation Risk Estimate': np.format_float_scientific(np.min(val_score_pca_mean))}\n",
    "            self.dict_cv_pca = dict_cv_pca\n",
    "            print(dict_cv_pca)\n",
    "    \n",
    "        return(train_pca_curve_err, val_pca_curve_err)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine_Learning",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
